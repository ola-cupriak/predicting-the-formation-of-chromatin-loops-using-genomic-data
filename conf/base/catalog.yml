# Data preprocessing
cells2names:
  type: yaml.YAMLDataSet
  filepath: data/01_raw/cells2names.yml


HiC_loops_annoatations:
  type: PartitionedDataSet
  path: data/01_raw/HiC_loops_annotations
  dataset: 
    type: pandas.CSVDataSet
    load_args:
      delimiter: "\t"
  filename_suffix: ".txt"


DNAse_seq_peaks:
  type: PartitionedDataSet
  path: data/01_raw/DNase_seq_peaks
  dataset: 
    type: pandas.CSVDataSet
    load_args:
      delimiter: "\t"
      usecols: [0, 1, 2]
      names: ['chr', 'start', 'end']
      dtype: {'chr': 'string', 'start': 'int32', 'end': 'int32'}
  filename_suffix: ".bed"


DNAse_seq_bigWig:
  type: PartitionedDataSet
  path: data/01_raw/DNase_seq_bigWig
  dataset: predicting_the_formation_of_chromatin_loops_using_genomic_data.extras.datasets.path_dataset.PathDataSet
  filename_suffix: ".bigWig"


CTCF_ChIP_seq_peaks:
  type: PartitionedDataSet
  path: data/01_raw/CTCF_ChIP_seq_peaks
  dataset: 
    type: pandas.CSVDataSet
    load_args:
      delimiter: "\t"
      usecols: [0, 1, 2]
      names: ['chr', 'start', 'end']
  filename_suffix: ".bed"


CTCF_ChIP_seq_bigWig:
  type: PartitionedDataSet
  path: data/01_raw/CTCF_ChIP_seq_bigWig
  dataset: predicting_the_formation_of_chromatin_loops_using_genomic_data.extras.datasets.path_dataset.PathDataSet
  filename_suffix: ".bigWig"


merged_HiC_loops_anotations:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/merged_HiC_looplist.csv
  load_args:
    delimiter: "\t"
  save_args:
    sep: "\t"

  
merged_DNase_seq_peaks:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/merged_DNase_seq_peaks.csv
  load_args:
    delimiter: "\t"
  save_args:
    sep: "\t"


overlaps_HiC_loops_DNase_seq_named:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/overlaps_HiC_loops_DNase_seq.csv
  load_args:
    delimiter: "\t"
  save_args:
    sep: "\t"


motifs_found_anchors_with_open_chromatin:
  type: pandas.ParquetDataSet
  filepath: data/02_intermediate/motifs_found_anchors_with_open_chromatin.parquet
  load_args:
    engine: "pyarrow"
  save_args:
    engine: "pyarrow"

  
combined_functional_genomics_data:
  type: PartitionedDataSet
  path: data/03_primary
  dataset: 
    type: pandas.ParquetDataSet
    load_args:
      engine: "pyarrow"
    save_args:
      engine: "pyarrow"
  filename_suffix: ".parquet"


concatenated_combined_functional_genomics_data:
  type: pandas.ParquetDataSet
  filepath: data/04_feature/concatenated_combined_functional_genomics_data.parquet
  load_args:
    engine: "pyarrow"
  save_args:
    engine: "pyarrow"

# Model training

# GM12878.random_forest_model:
#   filepath: data/06_models/GM12878_rf.pkl
#   type: pickle.PickleDataSet

# HeLa.random_forest_model:
#   filepath: data/06_models/HeLa_rf.pkl
#   type: pickle.PickleDataSet

# HMEC.random_forest_model:
#   filepath: data/06_models/HMEC_rf.pkl
#   type: pickle.PickleDataSet

# HUVEC.random_forest_model:
#   filepath: data/06_models/HUVEC_rf.pkl
#   type: pickle.PickleDataSet

# NHEK.random_forest_model:
#   filepath: data/06_models/NHEK_rf.pkl
#   type: pickle.PickleDataSet

# K562.random_forest_model:
#   filepath: data/06_models/K562_rf.pkl
#   type: pickle.PickleDataSet

# IMR90.random_forest_model:
#   filepath: data/06_models/IMR90_rf.pkl
#   type: pickle.PickleDataSet


# within.split_data_idxes:
#   type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
#   data_set:
#       type: PartitionedDataSet
#       path: data/05_model_input/within_splits
#       dataset: 
#         type: ???

# across.split_data_idxes:
#   type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
#   data_set:
#       type: PartitionedDataSet
#       path: data/05_model_input/across_splits
#       dataset: 
#         type: ???

# models

within.logistic_regression_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/within_logistic_regression_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

across.logistic_regression_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/across_logistic_regression_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

within.random_forest_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/within_random_forest_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

across.random_forest_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/across_random_forest_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

within.lightgbm_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/within_lightgbm_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

across.lightgbm_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/across_lightgbm_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

within.xgboost_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/within_xgboost_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

across.xgboost_models:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/06_models/across_xgboost_models
      dataset: 
        type: pickle.PickleDataSet
      filename_suffix: ".pkl"

# metrics
within.logistic_regression_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/within_logistic_regression_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

across.logistic_regression_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/across_logistic_regression_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

within.random_forest_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/within_random_forest_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

across.random_forest_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/across_random_forest_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

within.lightgbm_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/within_lightgbm_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

across.lightgbm_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/across_lightgbm_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

within.xgboost_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/within_xgboost_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"

across.xgboost_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet
  data_set:
      type: PartitionedDataSet
      path: data/07_model_output/across_xgboost_metrics
      dataset: 
        type: yaml.YAMLDataSet
      filename_suffix: ".txt"